{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0cc588f",
   "metadata": {
    "id": "c0cc588f"
   },
   "source": [
    "# Text Classification\n",
    "\n",
    "We are using Natural Language Processing with Disaster Tweets Kaggle dataset. The data is comprised of tweets, and our objective is to forecast which tweets are associated with a tragedy. This may enhance reaction times for a variety of interested parties, including police forces, fire departments, and news organisations, among others. We will do text categorization using predictive machine learning models, which is a subset of natural language processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91df8baa",
   "metadata": {
    "id": "91df8baa",
    "outputId": "4964435a-25cc-4ef9-b1a5-5406488a2c69"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Spark\\\\spark-3.0.3-bin-hadoop2.7'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614a2e21",
   "metadata": {
    "id": "614a2e21"
   },
   "source": [
    "Starting the Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc907c1",
   "metadata": {
    "id": "cbc907c1"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"NLP\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f0151f",
   "metadata": {
    "id": "b4f0151f"
   },
   "source": [
    "Import Important modules required "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a971d950",
   "metadata": {
    "id": "a971d950"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline \n",
    "from pyspark.ml.feature import CountVectorizer,StringIndexer, RegexTokenizer,StopWordsRemover\n",
    "from pyspark.sql.functions import col, udf,regexp_replace,isnull\n",
    "from pyspark.sql.types import StringType,IntegerType\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ae8f05",
   "metadata": {
    "id": "a0ae8f05"
   },
   "source": [
    "Now we are loading the dataset uci-news-aggregator.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ec274d",
   "metadata": {
    "id": "25ec274d",
    "outputId": "217070c0-1464-44e6-9d71-3a2135379042"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: string (nullable = true)\n",
      " |-- TITLE: string (nullable = true)\n",
      " |-- URL: string (nullable = true)\n",
      " |-- PUBLISHER: string (nullable = true)\n",
      " |-- CATEGORY: string (nullable = true)\n",
      " |-- STORY: string (nullable = true)\n",
      " |-- HOSTNAME: string (nullable = true)\n",
      " |-- TIMESTAMP: string (nullable = true)\n",
      "\n",
      "+---+--------------------+--------------------+--------------------+--------+--------------------+--------------------+-------------+\n",
      "| ID|               TITLE|                 URL|           PUBLISHER|CATEGORY|               STORY|            HOSTNAME|    TIMESTAMP|\n",
      "+---+--------------------+--------------------+--------------------+--------+--------------------+--------------------+-------------+\n",
      "|  1|Fed official says...|http://www.latime...|   Los Angeles Times|       b|ddUyU0VZz0BRneMio...|     www.latimes.com|1394470370698|\n",
      "|  2|Fed's Charles Plo...|http://www.livemi...|            Livemint|       b|ddUyU0VZz0BRneMio...|    www.livemint.com|1394470371207|\n",
      "|  3|US open: Stocks f...|http://www.ifamag...|        IFA Magazine|       b|ddUyU0VZz0BRneMio...| www.ifamagazine.com|1394470371550|\n",
      "|  4|Fed risks falling...|http://www.ifamag...|        IFA Magazine|       b|ddUyU0VZz0BRneMio...| www.ifamagazine.com|1394470371793|\n",
      "|  5|Fed's Plosser: Na...|http://www.moneyn...|           Moneynews|       b|ddUyU0VZz0BRneMio...|   www.moneynews.com|1394470372027|\n",
      "|  6|Plosser: Fed May ...|http://www.nasdaq...|              NASDAQ|       b|ddUyU0VZz0BRneMio...|      www.nasdaq.com|1394470372212|\n",
      "|  7|Fed's Plosser: Ta...|http://www.market...|         MarketWatch|       b|ddUyU0VZz0BRneMio...| www.marketwatch.com|1394470372405|\n",
      "|  8|Fed's Plosser exp...|http://www.fxstre...|        FXstreet.com|       b|ddUyU0VZz0BRneMio...|    www.fxstreet.com|1394470372615|\n",
      "|  9|US jobs growth la...|http://economicti...|      Economic Times|       b|ddUyU0VZz0BRneMio...|economictimes.ind...|1394470372792|\n",
      "| 10|ECB unlikely to e...|http://www.iii.co...|Interactive Investor|       b|dPhGU51DcrolUIMxb...|       www.iii.co.uk|1394470501265|\n",
      "| 11|ECB unlikely to e...|http://in.reuters...|       Reuters India|       b|dPhGU51DcrolUIMxb...|      in.reuters.com|1394470501410|\n",
      "| 12|EU's half-baked b...|http://blogs.reut...| Reuters UK \\(blog\\)|       b|dPhGU51DcrolUIMxb...|   blogs.reuters.com|1394470501587|\n",
      "| 13|Europe reaches cr...|http://in.reuters...|             Reuters|       b|dPhGU51DcrolUIMxb...|      in.reuters.com|1394470501755|\n",
      "| 14|ECB FOCUS-Stronge...|http://in.reuters...|             Reuters|       b|dPhGU51DcrolUIMxb...|      in.reuters.com|1394470501948|\n",
      "| 15|EU aims for deal ...|http://main.omano...| Oman Daily Observer|       b|dPhGU51DcrolUIMxb...|main.omanobserver.om|1394470502141|\n",
      "| 16|Forex - Pound dro...|http://www.nasdaq...|              NASDAQ|       b|dPhGU51DcrolUIMxb...|      www.nasdaq.com|1394470502316|\n",
      "| 17|Noyer Says Strong...|http://www.sfgate...|San Francisco Chr...|       b|dPhGU51DcrolUIMxb...|      www.sfgate.com|1394470502543|\n",
      "| 18|EU Week Ahead Mar...|http://blogs.wsj....|Wall Street Journ...|       b|dPhGU51DcrolUIMxb...|       blogs.wsj.com|1394470502744|\n",
      "| 19|ECB member Noyer ...|http://www.ifamag...|        IFA Magazine|       b|dPhGU51DcrolUIMxb...| www.ifamagazine.com|1394470502946|\n",
      "| 20|Euro Anxieties Wa...|http://www.busine...|        Businessweek|       b|dPhGU51DcrolUIMxb...|www.businessweek.com|1394470503148|\n",
      "+---+--------------------+--------------------+--------------------+--------+--------------------+--------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.cache of DataFrame[ID: string, TITLE: string, URL: string, PUBLISHER: string, CATEGORY: string, STORY: string, HOSTNAME: string, TIMESTAMP: string]>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read news csv dataset from the working directory\n",
    "news_data = spark.read.csv('uci-news-aggregator.csv',header= True)\n",
    "news_data.printSchema()\n",
    "news_data.show()\n",
    "#news_data = news_data.limit(300)\n",
    "#news_data.cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a520a22",
   "metadata": {
    "id": "2a520a22"
   },
   "source": [
    "We can check the count of totalitems in the dataset for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4fcc97",
   "metadata": {
    "id": "ca4fcc97",
    "outputId": "bdea19fd-348e-4fe3-d046-fb5d3d7c95f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count data items present in the set\n",
    "news_data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00df7f9c",
   "metadata": {
    "id": "00df7f9c"
   },
   "source": [
    "We are selecting the titles of tweets and the corresponding category of each tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bab7451",
   "metadata": {
    "id": "7bab7451",
    "outputId": "41616eda-9f6c-4efe-b8f8-9b6748580a0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|               TITLE|CATEGORY|\n",
      "+--------------------+--------+\n",
      "|Fed official says...|       b|\n",
      "|Fed's Charles Plo...|       b|\n",
      "|US open: Stocks f...|       b|\n",
      "|Fed risks falling...|       b|\n",
      "|Fed's Plosser: Na...|       b|\n",
      "|Plosser: Fed May ...|       b|\n",
      "|Fed's Plosser: Ta...|       b|\n",
      "|Fed's Plosser exp...|       b|\n",
      "|US jobs growth la...|       b|\n",
      "|ECB unlikely to e...|       b|\n",
      "|ECB unlikely to e...|       b|\n",
      "|EU's half-baked b...|       b|\n",
      "|Europe reaches cr...|       b|\n",
      "|ECB FOCUS-Stronge...|       b|\n",
      "|EU aims for deal ...|       b|\n",
      "|Forex - Pound dro...|       b|\n",
      "|Noyer Says Strong...|       b|\n",
      "|EU Week Ahead Mar...|       b|\n",
      "|ECB member Noyer ...|       b|\n",
      "|Euro Anxieties Wa...|       b|\n",
      "+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#select the titles of tweets corresponding to category\n",
    "title_category = news_data.select(\"TITLE\",\"CATEGORY\")\n",
    "title_category.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd72e0d",
   "metadata": {
    "id": "cfd72e0d"
   },
   "source": [
    "This is the custom function definition to count the null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748d0cef",
   "metadata": {
    "id": "748d0cef"
   },
   "outputs": [],
   "source": [
    "#definition to count the null values\n",
    "def null_value_count(df):\n",
    "  null_columns_counts = []\n",
    "  numRows = df.count()\n",
    "  for k in df.columns:\n",
    "    nullRows = df.where(col(k).isNull()).count()\n",
    "    if(nullRows > 0):\n",
    "      temp = k,nullRows\n",
    "      null_columns_counts.append(temp)\n",
    "  return(null_columns_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeaa0a96",
   "metadata": {
    "id": "aeaa0a96"
   },
   "source": [
    "We are applying the custom function to the data frame title_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b9d67a",
   "metadata": {
    "id": "11b9d67a"
   },
   "outputs": [],
   "source": [
    "null_columns_count_list = null_value_count(title_category)\n",
    "#spark.createDataFrame(null_columns_count_list, ['Column_With_Null_Value', 'Null_Values_Count']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1840e9",
   "metadata": {
    "id": "3b1840e9"
   },
   "source": [
    "# Cleaning the dataset\n",
    "\n",
    "Now we can drop the null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534b2a42",
   "metadata": {
    "id": "534b2a42",
    "outputId": "2fb420ec-4f19-4a1b-ec68-39b85f9b0c3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------+--------+\n",
      "|TITLE                                                                      |CATEGORY|\n",
      "+---------------------------------------------------------------------------+--------+\n",
      "|Fed official says weak data caused by weather, should not slow taper       |b       |\n",
      "|Fed's Charles Plosser sees high bar for change in pace of tapering         |b       |\n",
      "|US open: Stocks fall after Fed official hints at accelerated tapering      |b       |\n",
      "|Fed risks falling 'behind the curve', Charles Plosser says                 |b       |\n",
      "|Fed's Plosser: Nasty Weather Has Curbed Job Growth                         |b       |\n",
      "|Plosser: Fed May Have to Accelerate Tapering Pace                          |b       |\n",
      "|Fed's Plosser: Taper pace may be too slow                                  |b       |\n",
      "|Fed's Plosser expects US unemployment to fall to 6.2% by the end of 2014   |b       |\n",
      "|US jobs growth last month hit by weather:Fed President Charles Plosser     |b       |\n",
      "|ECB unlikely to end sterilisation of SMP purchases - traders               |b       |\n",
      "|ECB unlikely to end sterilization of SMP purchases: traders                |b       |\n",
      "|EU's half-baked bank union could work                                      |b       |\n",
      "|Europe reaches crunch point on banking union                               |b       |\n",
      "|ECB FOCUS-Stronger euro drowns out ECB's message to keep rates low for  ...|b       |\n",
      "|EU aims for deal on tackling failing banks                                 |b       |\n",
      "|Forex - Pound drops to one-month lows against euro                         |b       |\n",
      "|Noyer Says Strong Euro Creates Unwarranted Economic Pressure               |b       |\n",
      "|EU Week Ahead March 10-14: Bank Resolution, Transparency, Ukraine          |b       |\n",
      "|ECB member Noyer is 'very open to all kinds of tools'                      |b       |\n",
      "|Euro Anxieties Wane as Bunds Top Treasuries, Spain Debt Rallies            |b       |\n",
      "+---------------------------------------------------------------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Drop null and not available values\n",
    "title_category = title_category.dropna()\n",
    "title_category.count()\n",
    "title_category.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbad8a1",
   "metadata": {
    "id": "edbad8a1"
   },
   "source": [
    "We are counting the distinct casses from the category column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8840cdd",
   "metadata": {
    "id": "f8840cdd",
    "outputId": "51ae59c9-9c95-47f7-d9b0-db987c9c3d33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Category|count|\n",
      "+--------+-----+\n",
      "|b       |299  |\n",
      "|GigaOM  |1    |\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#count the distinct category available in the dataset\n",
    "title_category.select(\"Category\").distinct().count()\n",
    "title_category.groupBy(\"Category\").count().orderBy(col(\"count\").desc()).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d1a217",
   "metadata": {
    "id": "47d1a217",
    "outputId": "9635f612-cb18-425b-e612-8839b1960563"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------+-----+\n",
      "|TITLE                                                                      |count|\n",
      "+---------------------------------------------------------------------------+-----+\n",
      "|Fed official says weak data caused by weather, should not slow taper       |1    |\n",
      "|Fed's Charles Plosser sees high bar for change in pace of tapering         |1    |\n",
      "|US open: Stocks fall after Fed official hints at accelerated tapering      |1    |\n",
      "|Fed risks falling 'behind the curve', Charles Plosser says                 |1    |\n",
      "|Fed's Plosser: Nasty Weather Has Curbed Job Growth                         |1    |\n",
      "|Plosser: Fed May Have to Accelerate Tapering Pace                          |1    |\n",
      "|Fed's Plosser: Taper pace may be too slow                                  |1    |\n",
      "|Fed's Plosser expects US unemployment to fall to 6.2% by the end of 2014   |1    |\n",
      "|US jobs growth last month hit by weather:Fed President Charles Plosser     |1    |\n",
      "|ECB unlikely to end sterilisation of SMP purchases - traders               |1    |\n",
      "|ECB unlikely to end sterilization of SMP purchases: traders                |1    |\n",
      "|EU's half-baked bank union could work                                      |1    |\n",
      "|Europe reaches crunch point on banking union                               |1    |\n",
      "|ECB FOCUS-Stronger euro drowns out ECB's message to keep rates low for  ...|1    |\n",
      "|EU aims for deal on tackling failing banks                                 |1    |\n",
      "|Forex - Pound drops to one-month lows against euro                         |1    |\n",
      "|Noyer Says Strong Euro Creates Unwarranted Economic Pressure               |1    |\n",
      "|EU Week Ahead March 10-14: Bank Resolution, Transparency, Ukraine          |1    |\n",
      "|ECB member Noyer is 'very open to all kinds of tools'                      |1    |\n",
      "|Euro Anxieties Wane as Bunds Top Treasuries, Spain Debt Rallies            |1    |\n",
      "+---------------------------------------------------------------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "title_category.groupBy(\"TITLE\").count().orderBy(col(\"count\").desc()).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d598390",
   "metadata": {
    "id": "0d598390"
   },
   "source": [
    "Now let us remove the numbers present in the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e67a8cd",
   "metadata": {
    "id": "1e67a8cd",
    "outputId": "66ea4c1a-79c6-4af0-a8dd-3af1ba66b20a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------+---------------------------------------------------------------------------+\n",
      "|TITLE                                                                      |only_str                                                                   |\n",
      "+---------------------------------------------------------------------------+---------------------------------------------------------------------------+\n",
      "|Fed official says weak data caused by weather, should not slow taper       |Fed official says weak data caused by weather, should not slow taper       |\n",
      "|Fed's Charles Plosser sees high bar for change in pace of tapering         |Fed's Charles Plosser sees high bar for change in pace of tapering         |\n",
      "|US open: Stocks fall after Fed official hints at accelerated tapering      |US open: Stocks fall after Fed official hints at accelerated tapering      |\n",
      "|Fed risks falling 'behind the curve', Charles Plosser says                 |Fed risks falling 'behind the curve', Charles Plosser says                 |\n",
      "|Fed's Plosser: Nasty Weather Has Curbed Job Growth                         |Fed's Plosser: Nasty Weather Has Curbed Job Growth                         |\n",
      "|Plosser: Fed May Have to Accelerate Tapering Pace                          |Plosser: Fed May Have to Accelerate Tapering Pace                          |\n",
      "|Fed's Plosser: Taper pace may be too slow                                  |Fed's Plosser: Taper pace may be too slow                                  |\n",
      "|Fed's Plosser expects US unemployment to fall to 6.2% by the end of 2014   |Fed's Plosser expects US unemployment to fall to .% by the end of          |\n",
      "|US jobs growth last month hit by weather:Fed President Charles Plosser     |US jobs growth last month hit by weather:Fed President Charles Plosser     |\n",
      "|ECB unlikely to end sterilisation of SMP purchases - traders               |ECB unlikely to end sterilisation of SMP purchases - traders               |\n",
      "|ECB unlikely to end sterilization of SMP purchases: traders                |ECB unlikely to end sterilization of SMP purchases: traders                |\n",
      "|EU's half-baked bank union could work                                      |EU's half-baked bank union could work                                      |\n",
      "|Europe reaches crunch point on banking union                               |Europe reaches crunch point on banking union                               |\n",
      "|ECB FOCUS-Stronger euro drowns out ECB's message to keep rates low for  ...|ECB FOCUS-Stronger euro drowns out ECB's message to keep rates low for  ...|\n",
      "|EU aims for deal on tackling failing banks                                 |EU aims for deal on tackling failing banks                                 |\n",
      "|Forex - Pound drops to one-month lows against euro                         |Forex - Pound drops to one-month lows against euro                         |\n",
      "|Noyer Says Strong Euro Creates Unwarranted Economic Pressure               |Noyer Says Strong Euro Creates Unwarranted Economic Pressure               |\n",
      "|EU Week Ahead March 10-14: Bank Resolution, Transparency, Ukraine          |EU Week Ahead March -: Bank Resolution, Transparency, Ukraine              |\n",
      "|ECB member Noyer is 'very open to all kinds of tools'                      |ECB member Noyer is 'very open to all kinds of tools'                      |\n",
      "|Euro Anxieties Wane as Bunds Top Treasuries, Spain Debt Rallies            |Euro Anxieties Wane as Bunds Top Treasuries, Spain Debt Rallies            |\n",
      "+---------------------------------------------------------------------------+---------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#clean numbers and other unwanted characters from the tweets\n",
    "title_category = title_category.withColumn(\"only_str\",regexp_replace(col('TITLE'), '\\d+', ''))\n",
    "title_category.select(\"TITLE\",\"only_str\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49f034f",
   "metadata": {
    "id": "b49f034f"
   },
   "source": [
    "Split the text into constituent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dae25af",
   "metadata": {
    "id": "1dae25af",
    "outputId": "c3c1dd8f-b68d-422f-a1b4-690ac22ad251"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+--------------------+--------------------+\n",
      "|               TITLE|CATEGORY|            only_str|               words|\n",
      "+--------------------+--------+--------------------+--------------------+\n",
      "|Fed official says...|       b|Fed official says...|[fed, official, s...|\n",
      "|Fed's Charles Plo...|       b|Fed's Charles Plo...|[fed, s, charles,...|\n",
      "|US open: Stocks f...|       b|US open: Stocks f...|[us, open, stocks...|\n",
      "|Fed risks falling...|       b|Fed risks falling...|[fed, risks, fall...|\n",
      "|Fed's Plosser: Na...|       b|Fed's Plosser: Na...|[fed, s, plosser,...|\n",
      "|Plosser: Fed May ...|       b|Plosser: Fed May ...|[plosser, fed, ma...|\n",
      "|Fed's Plosser: Ta...|       b|Fed's Plosser: Ta...|[fed, s, plosser,...|\n",
      "|Fed's Plosser exp...|       b|Fed's Plosser exp...|[fed, s, plosser,...|\n",
      "|US jobs growth la...|       b|US jobs growth la...|[us, jobs, growth...|\n",
      "|ECB unlikely to e...|       b|ECB unlikely to e...|[ecb, unlikely, t...|\n",
      "|ECB unlikely to e...|       b|ECB unlikely to e...|[ecb, unlikely, t...|\n",
      "|EU's half-baked b...|       b|EU's half-baked b...|[eu, s, half, bak...|\n",
      "|Europe reaches cr...|       b|Europe reaches cr...|[europe, reaches,...|\n",
      "|ECB FOCUS-Stronge...|       b|ECB FOCUS-Stronge...|[ecb, focus, stro...|\n",
      "|EU aims for deal ...|       b|EU aims for deal ...|[eu, aims, for, d...|\n",
      "|Forex - Pound dro...|       b|Forex - Pound dro...|[forex, pound, dr...|\n",
      "|Noyer Says Strong...|       b|Noyer Says Strong...|[noyer, says, str...|\n",
      "|EU Week Ahead Mar...|       b|EU Week Ahead Mar...|[eu, week, ahead,...|\n",
      "|ECB member Noyer ...|       b|ECB member Noyer ...|[ecb, member, noy...|\n",
      "|Euro Anxieties Wa...|       b|Euro Anxieties Wa...|[euro, anxieties,...|\n",
      "+--------------------+--------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#split the text to tokens using tokenizer\n",
    "#https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.ml.feature.RegexTokenizer.html\n",
    "regex_tokenizer = RegexTokenizer(inputCol=\"only_str\", outputCol=\"words\", pattern=\"\\\\W\")\n",
    "raw_words = regex_tokenizer.transform(title_category)\n",
    "raw_words.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1526619",
   "metadata": {
    "id": "d1526619"
   },
   "source": [
    "Remove the stop words from segregated list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d5434a",
   "metadata": {
    "id": "94d5434a",
    "outputId": "dcba91d6-c295-4d88-9199-da8e44db4e52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------+-------------------------------------------------------------------------------+\n",
      "|words                                                                                |filtered                                                                       |\n",
      "+-------------------------------------------------------------------------------------+-------------------------------------------------------------------------------+\n",
      "|[fed, official, says, weak, data, caused, by, weather, should, not, slow, taper]     |[fed, official, says, weak, data, caused, weather, slow, taper]                |\n",
      "|[fed, s, charles, plosser, sees, high, bar, for, change, in, pace, of, tapering]     |[fed, charles, plosser, sees, high, bar, change, pace, tapering]               |\n",
      "|[us, open, stocks, fall, after, fed, official, hints, at, accelerated, tapering]     |[us, open, stocks, fall, fed, official, hints, accelerated, tapering]          |\n",
      "|[fed, risks, falling, behind, the, curve, charles, plosser, says]                    |[fed, risks, falling, behind, curve, charles, plosser, says]                   |\n",
      "|[fed, s, plosser, nasty, weather, has, curbed, job, growth]                          |[fed, plosser, nasty, weather, curbed, job, growth]                            |\n",
      "|[plosser, fed, may, have, to, accelerate, tapering, pace]                            |[plosser, fed, may, accelerate, tapering, pace]                                |\n",
      "|[fed, s, plosser, taper, pace, may, be, too, slow]                                   |[fed, plosser, taper, pace, may, slow]                                         |\n",
      "|[fed, s, plosser, expects, us, unemployment, to, fall, to, by, the, end, of]         |[fed, plosser, expects, us, unemployment, fall, end]                           |\n",
      "|[us, jobs, growth, last, month, hit, by, weather, fed, president, charles, plosser]  |[us, jobs, growth, last, month, hit, weather, fed, president, charles, plosser]|\n",
      "|[ecb, unlikely, to, end, sterilisation, of, smp, purchases, traders]                 |[ecb, unlikely, end, sterilisation, smp, purchases, traders]                   |\n",
      "|[ecb, unlikely, to, end, sterilization, of, smp, purchases, traders]                 |[ecb, unlikely, end, sterilization, smp, purchases, traders]                   |\n",
      "|[eu, s, half, baked, bank, union, could, work]                                       |[eu, half, baked, bank, union, work]                                           |\n",
      "|[europe, reaches, crunch, point, on, banking, union]                                 |[europe, reaches, crunch, point, banking, union]                               |\n",
      "|[ecb, focus, stronger, euro, drowns, out, ecb, s, message, to, keep, rates, low, for]|[ecb, focus, stronger, euro, drowns, ecb, message, keep, rates, low]           |\n",
      "|[eu, aims, for, deal, on, tackling, failing, banks]                                  |[eu, aims, deal, tackling, failing, banks]                                     |\n",
      "|[forex, pound, drops, to, one, month, lows, against, euro]                           |[forex, pound, drops, one, month, lows, euro]                                  |\n",
      "|[noyer, says, strong, euro, creates, unwarranted, economic, pressure]                |[noyer, says, strong, euro, creates, unwarranted, economic, pressure]          |\n",
      "|[eu, week, ahead, march, bank, resolution, transparency, ukraine]                    |[eu, week, ahead, march, bank, resolution, transparency, ukraine]              |\n",
      "|[ecb, member, noyer, is, very, open, to, all, kinds, of, tools]                      |[ecb, member, noyer, open, kinds, tools]                                       |\n",
      "|[euro, anxieties, wane, as, bunds, top, treasuries, spain, debt, rallies]            |[euro, anxieties, wane, bunds, top, treasuries, spain, debt, rallies]          |\n",
      "+-------------------------------------------------------------------------------------+-------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Remove and segregate stop words form the word list like for, by, in etc.\n",
    "#https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.feature.StopWordsRemover.html\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "words_df = remover.transform(raw_words)\n",
    "words_df.select(\"words\",\"filtered\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7990c213",
   "metadata": {
    "id": "7990c213"
   },
   "source": [
    "The category column in the dataframe can now be mapped to categoryIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdddab39",
   "metadata": {
    "id": "bdddab39",
    "outputId": "c98ddc9d-a3c6-4143-ebba-8c0eba8aa551"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+\n",
      "|CATEGORY|categoryIndex|\n",
      "+--------+-------------+\n",
      "|       b|          0.0|\n",
      "|       b|          0.0|\n",
      "|       b|          0.0|\n",
      "|       b|          0.0|\n",
      "|       b|          0.0|\n",
      "|       b|          0.0|\n",
      "|       b|          0.0|\n",
      "|       b|          0.0|\n",
      "|       b|          0.0|\n",
      "|       b|          0.0|\n",
      "|       b|          0.0|\n",
      "|       b|          0.0|\n",
      "|       b|          0.0|\n",
      "|       b|          0.0|\n",
      "|       b|          0.0|\n",
      "|       b|          0.0|\n",
      "|       b|          0.0|\n",
      "|       b|          0.0|\n",
      "|       b|          0.0|\n",
      "|       b|          0.0|\n",
      "+--------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Index the string for different category\n",
    "#https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.feature.StringIndexer.html\n",
    "indexer = StringIndexer(inputCol=\"CATEGORY\", outputCol=\"categoryIndex\")\n",
    "feature_data = indexer.fit(words_df).transform(words_df)\n",
    "feature_data.select(\"CATEGORY\",\"categoryIndex\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e215cd",
   "metadata": {
    "id": "10e215cd"
   },
   "source": [
    "Convert text into vectors of token counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca37104",
   "metadata": {
    "id": "3ca37104"
   },
   "outputs": [],
   "source": [
    "#converting text to vectors and count the tokens\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "cv = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\")\n",
    "model = cv.fit(feature_data)\n",
    "countVectorizer_feateures = model.transform(feature_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff14dc4",
   "metadata": {
    "id": "7ff14dc4"
   },
   "source": [
    "# Partition the dataset into training and test datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1efd33e",
   "metadata": {
    "id": "a1efd33e",
    "outputId": "c25d68fe-2158-4831-98d6-51dfae7fd4a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+--------------------+--------------------+--------------------+-------------+--------------------+\n",
      "|               TITLE|CATEGORY|            only_str|               words|            filtered|categoryIndex|            features|\n",
      "+--------------------+--------+--------------------+--------------------+--------------------+-------------+--------------------+\n",
      "|\"MtGox \"\"fraud ev...|  GigaOM|\"MtGox \"\"fraud ev...|[mtgox, fraud, ev...|[mtgox, fraud, ev...|          1.0|(625,[24,38,54,70...|\n",
      "|$5 20-piece chick...|       b|$ -piece chicken ...|[piece, chicken, ...|[piece, chicken, ...|          0.0|(625,[2,7,10,125,...|\n",
      "|'Hacked docs' pro...|       b|'Hacked docs' pro...|[hacked, docs, pr...|[hacked, docs, pr...|          0.0|(625,[22,24,28,30...|\n",
      "|10 Things You Nee...|       b| Things You Need ...|[things, you, nee...|[things, need, kn...|          0.0|(625,[155,171,178...|\n",
      "|10 Things You Nee...|       b| Things You Need ...|[things, you, nee...|[things, need, kn...|          0.0|(625,[155,182,183...|\n",
      "|A Secular Bull Ma...|       b|A Secular Bull Ma...|[a, secular, bull...|[secular, bull, m...|          0.0|(625,[4,11,506,52...|\n",
      "|Anonymous hackers...|       b|Anonymous hackers...|[anonymous, hacke...|[anonymous, hacke...|          0.0|(625,[8,24,28,30,...|\n",
      "|Anonymous hackers...|       b|Anonymous hackers...|[anonymous, hacke...|[anonymous, hacke...|          0.0|(625,[8,12,24,38,...|\n",
      "|Asia Worries Send...|       b|Asia Worries Send...|[asia, worries, s...|[asia, worries, s...|          0.0|(625,[5,114,166,4...|\n",
      "|Australian Bitcoi...|       b|Australian Bitcoi...|[australian, bitc...|[australian, bitc...|          0.0|(625,[0,1,3,91,15...|\n",
      "|Bitcoin Exchange ...|       b|Bitcoin Exchange ...|[bitcoin, exchang...|[bitcoin, exchang...|          0.0|(625,[0,1,2,3,13,...|\n",
      "|Bitcoin enthusias...|       b|Bitcoin enthusias...|[bitcoin, enthusi...|[bitcoin, enthusi...|          0.0|(625,[3,36,252,34...|\n",
      "|Bitcoin exchange ...|       b|Bitcoin exchange ...|[bitcoin, exchang...|[bitcoin, exchang...|          0.0|(625,[0,1,2,3,13,...|\n",
      "|Bitcoin exchange ...|       b|Bitcoin exchange ...|[bitcoin, exchang...|[bitcoin, exchang...|          0.0|(625,[0,1,2,3,13,...|\n",
      "|Bitcoin exchange ...|       b|Bitcoin exchange ...|[bitcoin, exchang...|[bitcoin, exchang...|          0.0|(625,[3,18,23,24,...|\n",
      "|Bitcoin exchange ...|       b|Bitcoin exchange ...|[bitcoin, exchang...|[bitcoin, exchang...|          0.0|(625,[3,18,23,24,...|\n",
      "|Bitcoin exchange ...|       b|Bitcoin exchange ...|[bitcoin, exchang...|[bitcoin, exchang...|          0.0|(625,[3,18,23,24,...|\n",
      "|Bitcoin exchange ...|       b|Bitcoin exchange ...|[bitcoin, exchang...|[bitcoin, exchang...|          0.0|(625,[3,18,37,104...|\n",
      "|Bitcoin exchange ...|       b|Bitcoin exchange ...|[bitcoin, exchang...|[bitcoin, exchang...|          0.0|(625,[3,18,23,37,...|\n",
      "|Bitcoin refuses t...|       b|Bitcoin refuses t...|[bitcoin, refuses...|[bitcoin, refuses...|          0.0|(625,[3,385,526],...|\n",
      "+--------------------+--------+--------------------+--------------------+--------------------+-------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+--------+--------------------+--------------------+--------------------+-------------+--------------------+\n",
      "|               TITLE|CATEGORY|            only_str|               words|            filtered|categoryIndex|            features|\n",
      "+--------------------+--------+--------------------+--------------------+--------------------+-------------+--------------------+\n",
      "|3 Predictions for...|       b| Predictions for ...|[predictions, for...|[predictions, new...|          0.0|(625,[36,145,409]...|\n",
      "|3 things to watch...|       b| things to watch ...|[things, to, watc...|[things, watch, m...|          0.0|(625,[2,7,10,155,...|\n",
      "|Bad loan triggers...|       b|Bad loan triggers...|[bad, loan, trigg...|[bad, loan, trigg...|          0.0|(625,[14,55,57,64...|\n",
      "|Bankrupt Exchange...|       b|Bankrupt Exchange...|[bankrupt, exchan...|[bankrupt, exchan...|          0.0|(625,[0,1,8,18,28...|\n",
      "|Bitcoin Exchange ...|       b|Bitcoin Exchange ...|[bitcoin, exchang...|[bitcoin, exchang...|          0.0|(625,[0,1,3,18,23...|\n",
      "|Bitcoin Mt. Gox C...|       b|Bitcoin Mt. Gox C...|[bitcoin, mt, gox...|[bitcoin, mt, gox...|          0.0|(625,[0,1,3,8,28,...|\n",
      "|Bitcoin credibili...|       b|Bitcoin credibili...|[bitcoin, credibi...|[bitcoin, credibi...|          0.0|(625,[3,165,311,3...|\n",
      "|Bitcoin exchange ...|       b|Bitcoin exchange ...|[bitcoin, exchang...|[bitcoin, exchang...|          0.0|(625,[0,1,2,3,13,...|\n",
      "|Bitcoin exchange ...|       b|Bitcoin exchange ...|[bitcoin, exchang...|[bitcoin, exchang...|          0.0|(625,[3,13,18,47,...|\n",
      "|Bitcoin's enthusi...|       b|Bitcoin's enthusi...|[bitcoin, s, enth...|[bitcoin, enthusi...|          0.0|(625,[3,36,68,252...|\n",
      "|Bull Still Chargi...|       b|Bull Still Chargi...|[bull, still, cha...|[bull, still, cha...|          0.0|(625,[11,46,67,24...|\n",
      "|Bull market still...|       b|Bull market still...|[bull, market, st...|[bull, market, st...|          0.0|(625,[4,11,46,426...|\n",
      "|Business growth i...|       b|Business growth i...|[business, growth...|[business, growth...|          0.0|(625,[19,81,97,10...|\n",
      "|Cryptocurrency Ne...|       b|Cryptocurrency Ne...|[cryptocurrency, ...|[cryptocurrency, ...|          0.0|(625,[0,1,3,86,30...|\n",
      "|Despite obstacles...|       b|Despite obstacles...|[despite, obstacl...|[despite, obstacl...|          0.0|(625,[4,11,83,99,...|\n",
      "|EBay asks shareho...|       b|EBay asks shareho...|[ebay, asks, shar...|[ebay, asks, shar...|          0.0|(625,[6,9,27,34,6...|\n",
      "|EBay rejects Icah...|       b|EBay rejects Icah...|[ebay, rejects, i...|[ebay, rejects, i...|          0.0|(625,[6,9,27,34,4...|\n",
      "|EBay urges shareh...|       b|EBay urges shareh...|[ebay, urges, sha...|[ebay, urges, sha...|          0.0|(625,[6,9,27,34,6...|\n",
      "|ECB FOCUS-Stronge...|       b|ECB FOCUS-Stronge...|[ecb, focus, stro...|[ecb, focus, stro...|          0.0|(625,[14,19,72,84...|\n",
      "|ECB's Noyer not H...|       b|ECB's Noyer not H...|[ecb, s, noyer, n...|[ecb, noyer, happ...|          0.0|(625,[14,19,42,73...|\n",
      "+--------------------+--------+--------------------+--------------------+--------------------+-------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#partition the data set into training and test sets\n",
    "(trainingData, testData) = countVectorizer_feateures.randomSplit([0.8, 0.2],seed = 11)\n",
    "trainingData.show()\n",
    "testData.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df21afb",
   "metadata": {
    "id": "1df21afb"
   },
   "source": [
    "# Model Training and Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eca5139",
   "metadata": {
    "id": "9eca5139"
   },
   "source": [
    "## Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e411887",
   "metadata": {
    "id": "3e411887"
   },
   "outputs": [],
   "source": [
    "#https://scikit-learn.org/stable/modules/naive_bayes.html\n",
    "nb = NaiveBayes(modelType=\"multinomial\",labelCol=\"categoryIndex\", featuresCol=\"features\")\n",
    "nbModel = nb.fit(trainingData)\n",
    "nb_predictions = nbModel.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0267532",
   "metadata": {
    "id": "e0267532",
    "outputId": "fb5ea116-8e47-4d5f-b73a-367b7aad872e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+\n",
      "|prediction|categoryIndex|            features|\n",
      "+----------+-------------+--------------------+\n",
      "|       0.0|          0.0|(625,[36,145,409]...|\n",
      "|       0.0|          0.0|(625,[2,7,10,155,...|\n",
      "|       0.0|          0.0|(625,[14,55,57,64...|\n",
      "|       0.0|          0.0|(625,[0,1,8,18,28...|\n",
      "|       0.0|          0.0|(625,[0,1,3,18,23...|\n",
      "|       0.0|          0.0|(625,[0,1,3,8,28,...|\n",
      "|       0.0|          0.0|(625,[3,165,311,3...|\n",
      "|       0.0|          0.0|(625,[0,1,2,3,13,...|\n",
      "|       0.0|          0.0|(625,[3,13,18,47,...|\n",
      "|       0.0|          0.0|(625,[3,36,68,252...|\n",
      "|       0.0|          0.0|(625,[11,46,67,24...|\n",
      "|       0.0|          0.0|(625,[4,11,46,426...|\n",
      "|       0.0|          0.0|(625,[19,81,97,10...|\n",
      "|       0.0|          0.0|(625,[0,1,3,86,30...|\n",
      "|       0.0|          0.0|(625,[4,11,83,99,...|\n",
      "|       0.0|          0.0|(625,[6,9,27,34,6...|\n",
      "|       0.0|          0.0|(625,[6,9,27,34,4...|\n",
      "|       0.0|          0.0|(625,[6,9,27,34,6...|\n",
      "|       0.0|          0.0|(625,[14,19,72,84...|\n",
      "|       0.0|          0.0|(625,[14,19,42,73...|\n",
      "|       0.0|          0.0|(625,[2,45,48,63,...|\n",
      "|       0.0|          0.0|(625,[48,60,63,15...|\n",
      "|       1.0|          0.0|(625,[35,36,149,1...|\n",
      "|       0.0|          0.0|(625,[5,60,74,97,...|\n",
      "|       0.0|          0.0|(625,[3,8,24,28,4...|\n",
      "|       0.0|          0.0|(625,[4,11,77,90,...|\n",
      "|       0.0|          0.0|(625,[6,9,12,117,...|\n",
      "|       0.0|          0.0|(625,[6,9,34,43,1...|\n",
      "|       0.0|          0.0|(625,[58,187,203,...|\n",
      "|       0.0|          0.0|(625,[0,1,2,13,16...|\n",
      "|       0.0|          0.0|(625,[23,141,191,...|\n",
      "|       0.0|          0.0|(625,[7,10,29,68,...|\n",
      "|       0.0|          0.0|(625,[7,10,20,355...|\n",
      "|       0.0|          0.0|(625,[7,10,20,45,...|\n",
      "|       0.0|          0.0|(625,[7,10,20,581...|\n",
      "|       0.0|          0.0|(625,[7,92,111,18...|\n",
      "|       0.0|          0.0|(625,[7,10,20,29,...|\n",
      "|       0.0|          0.0|(625,[2,7,10,17,8...|\n",
      "|       0.0|          0.0|(625,[7,10,125,14...|\n",
      "|       0.0|          0.0|(625,[0,1,12,22,5...|\n",
      "|       0.0|          0.0|(625,[0,1,2,13,16...|\n",
      "|       0.0|          0.0|(625,[0,1,2,13,16...|\n",
      "|       0.0|          0.0|(625,[8,24,98,106...|\n",
      "|       0.0|          0.0|(625,[19,32,42,74...|\n",
      "|       0.0|          0.0|(625,[48,60,63,15...|\n",
      "|       0.0|          0.0|(625,[215,415,460...|\n",
      "|       0.0|          0.0|(625,[15,21,26,29...|\n",
      "|       0.0|          0.0|(625,[5,15,26,29,...|\n",
      "|       0.0|          0.0|(625,[5,15,47,60,...|\n",
      "|       0.0|          0.0|(625,[5,45,56,253...|\n",
      "|       0.0|          0.0|(625,[0,1,16,88,3...|\n",
      "|       0.0|          0.0|(625,[15,17,33,35...|\n",
      "|       0.0|          0.0|(625,[2,5,15,17,2...|\n",
      "|       0.0|          0.0|(625,[2,17,25,35,...|\n",
      "|       0.0|          0.0|(625,[31,50,359,4...|\n",
      "|       0.0|          0.0|(625,[3,352,367,4...|\n",
      "|       0.0|          0.0|(625,[17,25,31,50...|\n",
      "|       0.0|          0.0|(625,[17,25,31,50...|\n",
      "|       0.0|          0.0|(625,[4,21,36,44,...|\n",
      "|       0.0|          0.0|(625,[6,9,27,62,2...|\n",
      "+----------+-------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_predictions.select(\"prediction\", \"categoryIndex\", \"features\").show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae08819f",
   "metadata": {
    "id": "ae08819f",
    "outputId": "c06c5aba-ab29-474b-9914-1f93ce133465"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of NaiveBayes is = 0.983333\n",
      "Test Error of NaiveBayes = 0.0166667 \n"
     ]
    }
   ],
   "source": [
    "#https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.evaluation.MulticlassClassificationEvaluator.html\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"categoryIndex\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "#https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.evaluation.BinaryClassificationEvaluator.html\n",
    "nb_accuracy = evaluator.evaluate(nb_predictions)\n",
    "print(\"Accuracy of NaiveBayes is = %g\"% (nb_accuracy))\n",
    "print(\"Test Error of NaiveBayes = %g \" % (1.0 - nb_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6a7f6b",
   "metadata": {
    "id": "3e6a7f6b"
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80efef2b",
   "metadata": {
    "id": "80efef2b"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "## Fitting the model\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "lr = LogisticRegression(featuresCol = 'features', labelCol = 'categoryIndex', maxIter=10)\n",
    "lrModel = lr.fit(trainingData)\n",
    "lrPreds = lrModel.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770aa79f",
   "metadata": {
    "id": "770aa79f",
    "outputId": "054f432d-c96d-4086-861e-c91e6fe0656d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression is = 1\n"
     ]
    }
   ],
   "source": [
    "## Evaluating the model\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"categoryIndex\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "lr_accuracy = evaluator.evaluate(lrPreds)\n",
    "print(\"Accuracy of Logistic Regression is = %g\"% (lr_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900ccda5",
   "metadata": {
    "id": "900ccda5"
   },
   "source": [
    "## Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6523a330",
   "metadata": {
    "id": "6523a330"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "## Fitting the model\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "dt = DecisionTreeClassifier(featuresCol = 'features', labelCol = 'categoryIndex', maxDepth = 3)\n",
    "dtModel = dt.fit(trainingData)\n",
    "dtPreds = dtModel.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9272dae8",
   "metadata": {
    "id": "9272dae8",
    "outputId": "42503b99-2e1a-486a-9224-a796dd13758b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Trees is = 1\n"
     ]
    }
   ],
   "source": [
    "## Evaluating the model\n",
    "#https://spark.apache.org/docs/latest/api/java/index.html?org/apache/spark/ml/evaluation/MulticlassClassificationEvaluator.html\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"categoryIndex\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "dt_accuracy = evaluator.evaluate(dtPreds)\n",
    "print(\"Accuracy of Decision Trees is = %g\"% (dt_accuracy))\n",
    "#Accuracy of Decision Trees is = 0.651034"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b415fcb5",
   "metadata": {
    "id": "b415fcb5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lab2_NLP_news_classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
