{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ffaad43",
   "metadata": {},
   "source": [
    "# Drift detection using alibi-detect package from SELDON.IO\n",
    "\n",
    "Install the alibi-detect from seldon.io using following techniques\n",
    "\n",
    "## With pip\n",
    "pip install alibi-detect\n",
    "\n",
    "## With conda\n",
    "\n",
    "### Install mamba package manager\n",
    "conda install mamba -n base -c conda-forge\n",
    "\n",
    "### To install alibi-detect with the default TensorFlow backend:\n",
    "\n",
    "mamba install -c conda-forge alibi-detect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cb9a6d",
   "metadata": {},
   "source": [
    "## Drift detection on diabetic data\n",
    "\n",
    "Here we are applying drift detection in diabetic dataset. The dataset contains both contineous data and categorical data. The drift detector applies feature-wise two-sample Kolmogorov-Smirnov (K-S) tests for the continuous numerical features and Chi-Squared tests for the categorical features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e7dbe8",
   "metadata": {},
   "source": [
    "To add PySpark to sys.path for running the code on the Jupyter IDE we are Using the package findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a16d3cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Spark\\\\spark-3.0.3-bin-hadoop2.7'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d365582",
   "metadata": {},
   "source": [
    "To perform any task on spark you need start a spark session, here we are starting a session for our logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "075121a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Logistic App\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d625be6e",
   "metadata": {},
   "source": [
    "To start, we are loading the diabetes dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7811bb41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2022-04-07 19:38:01--  https://raw.githubusercontent.com/ismayilsiyad/hpe_ml/main/diabetes.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 776415 (758K) [text/plain]\n",
      "Saving to: 'diabetes.csv.15'\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  6%  767K 1s\n",
      "    50K .......... .......... .......... .......... .......... 13% 1.12M 1s\n",
      "   100K .......... .......... .......... .......... .......... 19%  951K 1s\n",
      "   150K .......... .......... .......... .......... .......... 26% 1.09M 1s\n",
      "   200K .......... .......... .......... .......... .......... 32%  366K 1s\n",
      "   250K .......... .......... .......... .......... .......... 39% 42.3M 1s\n",
      "   300K .......... .......... .......... .......... .......... 46%  529K 1s\n",
      "   350K .......... .......... .......... .......... .......... 52%  406K 1s\n",
      "   400K .......... .......... .......... .......... .......... 59%  631K 0s\n",
      "   450K .......... .......... .......... .......... .......... 65%  355K 0s\n",
      "   500K .......... .......... .......... .......... .......... 72%  271K 0s\n",
      "   550K .......... .......... .......... .......... .......... 79%  377K 0s\n",
      "   600K .......... .......... .......... .......... .......... 85%  458K 0s\n",
      "   650K .......... .......... .......... .......... .......... 92%  388K 0s\n",
      "   700K .......... .......... .......... .......... .......... 98%  362K 0s\n",
      "   750K ........                                              100%  373K=1.5s\n",
      "\n",
      "2022-04-07 19:38:03 (507 KB/s) - 'diabetes.csv.15' saved [776415/776415]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PatientID: string (nullable = true)\n",
      " |-- Pregnancies: string (nullable = true)\n",
      " |-- PlasmaGlucose: string (nullable = true)\n",
      " |-- DiastolicBloodPressure: string (nullable = true)\n",
      " |-- TricepsThickness: string (nullable = true)\n",
      " |-- SerumInsulin: string (nullable = true)\n",
      " |-- BMI: string (nullable = true)\n",
      " |-- DiabetesPedigree: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- Diabetic: string (nullable = true)\n",
      "\n",
      "+---------+-----------+-------------+----------------------+----------------+------------+-----------+----------------+---+--------+\n",
      "|PatientID|Pregnancies|PlasmaGlucose|DiastolicBloodPressure|TricepsThickness|SerumInsulin|        BMI|DiabetesPedigree|Age|Diabetic|\n",
      "+---------+-----------+-------------+----------------------+----------------+------------+-----------+----------------+---+--------+\n",
      "|  1354778|          0|          171|                    80|              34|          23|43.50972593|     1.213191354| 21|       0|\n",
      "|  1147438|          8|           92|                    93|              47|          36|21.24057571|     0.158364981| 23|       0|\n",
      "|  1640031|          7|          115|                    47|              52|          35|41.51152348|     0.079018568| 23|       0|\n",
      "|  1883350|          9|          103|                    78|              25|         304|29.58219193|     1.282869847| 43|       1|\n",
      "|  1424119|          1|           85|                    59|              27|          35|42.60453585|     0.549541871| 22|       0|\n",
      "|  1619297|          0|           82|                    92|               9|         253|19.72416021|     0.103424498| 26|       0|\n",
      "|  1660149|          0|          133|                    47|              19|         227|21.94135672|     0.174159779| 21|       0|\n",
      "|  1458769|          0|           67|                    87|              43|          36| 18.2777226|      0.23616494| 26|       0|\n",
      "|  1201647|          8|           80|                    95|              33|          24|26.62492885|     0.443947388| 53|       1|\n",
      "|  1403912|          1|           72|                    31|              40|          42|36.88957571|     0.103943637| 26|       0|\n",
      "|  1943830|          1|           88|                    86|              11|          58|43.22504089|     0.230284623| 22|       0|\n",
      "|  1824483|          3|           94|                    96|              31|          36|21.29447943|     0.259020482| 23|       0|\n",
      "|  1848869|          5|          114|                   101|              43|          70|36.49531966|     0.079190164| 38|       1|\n",
      "|  1669231|          7|          110|                    82|              16|          44|36.08929341|     0.281276159| 25|       0|\n",
      "|  1683688|          0|          148|                    58|              11|         179|39.19207553|     0.160829008| 45|       0|\n",
      "|  1738587|          3|          109|                    77|              46|          61|19.84731197|     0.204345272| 21|       1|\n",
      "|  1884264|          3|          106|                    64|              25|          51| 29.0445728|     0.589188017| 42|       1|\n",
      "|  1485251|          1|          156|                    53|              15|         226|29.78619164|     0.203823525| 41|       1|\n",
      "|  1536832|          8|          117|                    39|              32|         164|21.23099598|     0.089362745| 25|       0|\n",
      "|  1438701|          3|          102|                   100|              25|         289|42.18572029|     0.175592826| 43|       1|\n",
      "+---------+-----------+-------------+----------------------+----------------+------------+-----------+----------------+---+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/ismayilsiyad/hpe_ml/main/diabetes.csv\n",
    "diabetes = spark.read.csv('diabetes.csv',header= True)\n",
    "diabetes.printSchema()\n",
    "diabetes.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de2ff7f",
   "metadata": {},
   "source": [
    "# Dropping unwanted columns\n",
    "\n",
    "We need to drop unwanted columns from the dataset. By looking into the dataset we can see columns 'PatientID' have no relevance in predicting the diabetes. To have this insight in a complex problem. we have to formulate the hypothesis and evaluation of the hypothesis should be done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efa7c0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Pregnancies: string (nullable = true)\n",
      " |-- PlasmaGlucose: string (nullable = true)\n",
      " |-- DiastolicBloodPressure: string (nullable = true)\n",
      " |-- TricepsThickness: string (nullable = true)\n",
      " |-- SerumInsulin: string (nullable = true)\n",
      " |-- BMI: string (nullable = true)\n",
      " |-- DiabetesPedigree: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- Diabetic: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "colm = 'PatientID'\n",
    "db_df = diabetes.select([column for column in diabetes.columns if column not in colm])\n",
    "db_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985b6624",
   "metadata": {},
   "source": [
    "# Changing the column datatype\n",
    "\n",
    "We need to change column datatype to float from the initial string datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "464136ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Pregnancies: float (nullable = true)\n",
      " |-- PlasmaGlucose: float (nullable = true)\n",
      " |-- DiastolicBloodPressure: float (nullable = true)\n",
      " |-- TricepsThickness: float (nullable = true)\n",
      " |-- SerumInsulin: float (nullable = true)\n",
      " |-- BMI: float (nullable = true)\n",
      " |-- DiabetesPedigree: float (nullable = true)\n",
      " |-- Age: float (nullable = true)\n",
      " |-- Diabetic: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "db_df = db_df.select(*(col(c).cast('float').alias(c) for c in db_df.columns))\n",
    "db_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2eb2e20",
   "metadata": {},
   "source": [
    "# Taking the count of the null and missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c9f8616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+----------------------+----------------+------------+---+----------------+---+--------+\n",
      "|Pregnancies|PlasmaGlucose|DiastolicBloodPressure|TricepsThickness|SerumInsulin|BMI|DiabetesPedigree|Age|Diabetic|\n",
      "+-----------+-------------+----------------------+----------------+------------+---+----------------+---+--------+\n",
      "|          0|            0|                     0|               0|           0|  0|               0|  0|       0|\n",
      "+-----------+-------------+----------------------+----------------+------------+---+----------------+---+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, count, isnan, when\n",
    "db_df.select([count(when(col(c).isNull(), c)).alias(c) for c in db_df.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae455ad3",
   "metadata": {},
   "source": [
    "## Importing Chi-square drift and Tabular drift modules from alibi-detect library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6c22eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from alibi_detect.cd import ChiSquareDrift, TabularDrift\n",
    "from alibi_detect.utils.saving import save_detector, load_detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91532df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+----------------------+----------------+------------+---------+----------------+----+--------+\n",
      "|Pregnancies|PlasmaGlucose|DiastolicBloodPressure|TricepsThickness|SerumInsulin|      BMI|DiabetesPedigree| Age|Diabetic|\n",
      "+-----------+-------------+----------------------+----------------+------------+---------+----------------+----+--------+\n",
      "|        0.0|        171.0|                  80.0|            34.0|        23.0|43.509727|       1.2131914|21.0|     0.0|\n",
      "|        8.0|         92.0|                  93.0|            47.0|        36.0|21.240576|      0.15836498|23.0|     0.0|\n",
      "|        7.0|        115.0|                  47.0|            52.0|        35.0|41.511524|      0.07901857|23.0|     0.0|\n",
      "|        9.0|        103.0|                  78.0|            25.0|       304.0|29.582191|       1.2828698|43.0|     1.0|\n",
      "|        1.0|         85.0|                  59.0|            27.0|        35.0|42.604534|       0.5495419|22.0|     0.0|\n",
      "|        0.0|         82.0|                  92.0|             9.0|       253.0|19.724161|       0.1034245|26.0|     0.0|\n",
      "|        0.0|        133.0|                  47.0|            19.0|       227.0|21.941357|      0.17415978|21.0|     0.0|\n",
      "|        0.0|         67.0|                  87.0|            43.0|        36.0|18.277723|      0.23616494|26.0|     0.0|\n",
      "|        8.0|         80.0|                  95.0|            33.0|        24.0| 26.62493|      0.44394737|53.0|     1.0|\n",
      "|        1.0|         72.0|                  31.0|            40.0|        42.0|36.889576|      0.10394364|26.0|     0.0|\n",
      "|        1.0|         88.0|                  86.0|            11.0|        58.0| 43.22504|      0.23028462|22.0|     0.0|\n",
      "|        3.0|         94.0|                  96.0|            31.0|        36.0| 21.29448|      0.25902048|23.0|     0.0|\n",
      "|        5.0|        114.0|                 101.0|            43.0|        70.0| 36.49532|     0.079190165|38.0|     1.0|\n",
      "|        7.0|        110.0|                  82.0|            16.0|        44.0|36.089294|      0.28127617|25.0|     0.0|\n",
      "|        0.0|        148.0|                  58.0|            11.0|       179.0|39.192074|      0.16082901|45.0|     0.0|\n",
      "|        3.0|        109.0|                  77.0|            46.0|        61.0|19.847311|      0.20434527|21.0|     1.0|\n",
      "|        3.0|        106.0|                  64.0|            25.0|        51.0|29.044573|      0.58918804|42.0|     1.0|\n",
      "|        1.0|        156.0|                  53.0|            15.0|       226.0|29.786192|      0.20382352|41.0|     1.0|\n",
      "|        8.0|        117.0|                  39.0|            32.0|       164.0|21.230995|      0.08936275|25.0|     0.0|\n",
      "|        3.0|        102.0|                 100.0|            25.0|       289.0| 42.18572|      0.17559282|43.0|     1.0|\n",
      "+-----------+-------------+----------------------+----------------+------------+---------+----------------+----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "db_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013b8c08",
   "metadata": {},
   "source": [
    "## Converting spark dataframe to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d783bb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "db_df_pd = np.array(db_df.select(\"*\").collect())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c9ed1025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 9)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_df_pd.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed7e96d",
   "metadata": {},
   "source": [
    "We split the data in a reference set and 2 test sets on which we test the data drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "99b070c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4500, 9), (4500, 9), (4500, 9))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_ref = 4500\n",
    "n_test = 4500\n",
    "\n",
    "X_ref, X_t0, X_t1 = db_df_pd[:n_ref], db_df_pd[n_ref:n_ref + n_test], db_df_pd[n_ref + n_test:n_ref + 2 * n_test]\n",
    "X_ref.shape, X_t0.shape, X_t1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675cf1cc",
   "metadata": {},
   "source": [
    "## Detect drift\n",
    "\n",
    "We need to provide the drift detector with the columns which contain categorical features so it knows which features require the Chi-Squared and which ones require the K-S univariate test. We can either provide a dict with as keys the column indices and as values the number of possible categories or just set the values to None and let the detector infer the number of categories from the reference data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35c2e62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "feature_names = ['Pregnancies', 'PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age','Diabetic']\n",
    "category_map = {8: ['0.0','1.0']}\n",
    "categories_per_feature = {f: None for f in list(category_map.keys())}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f90f7c",
   "metadata": {},
   "source": [
    "Next, we can initialize the detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36ee0f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd = TabularDrift(X_ref, p_val=.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97b4761",
   "metadata": {},
   "source": [
    "We can save the initialised detector and load it back:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19daf5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Directory my_path\\model does not exist.\n"
     ]
    }
   ],
   "source": [
    "filepath = 'my_path'  # change to directory where detector is saved\n",
    "save_detector(cd, filepath)\n",
    "cd = load_detector(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5b48e0",
   "metadata": {},
   "source": [
    "Next we can check whether the first test setis is drifting from the reference data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61d402c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drift? No!\n"
     ]
    }
   ],
   "source": [
    "preds = cd.predict(X_t0)\n",
    "labels = ['No!', 'Yes!']\n",
    "print('Drift? {}'.format(labels[preds['data']['is_drift']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc44f2c",
   "metadata": {},
   "source": [
    "It is possible to check the drift for each feature seperately. The preds dictionary also returns the K-S or Chi-Squared test statistics and p-value for each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62235c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregnancies -- K-S 0.005 -- p-value 1.000\n",
      "PlasmaGlucose -- K-S 0.022 -- p-value 0.243\n",
      "DiastolicBloodPressure -- K-S 0.028 -- p-value 0.064\n",
      "TricepsThickness -- K-S 0.021 -- p-value 0.288\n",
      "SerumInsulin -- K-S 0.017 -- p-value 0.520\n",
      "BMI -- K-S 0.013 -- p-value 0.844\n",
      "DiabetesPedigree -- K-S 0.018 -- p-value 0.486\n",
      "Age -- K-S 0.027 -- p-value 0.080\n",
      "Diabetic -- Chi2 0.010 -- p-value 0.976\n"
     ]
    }
   ],
   "source": [
    "for f in range(cd.n_features):\n",
    "    stat = 'Chi2' if f in list(categories_per_feature.keys()) else 'K-S'\n",
    "    fname = feature_names[f]\n",
    "    stat_val, p_val = preds['data']['distance'][f], preds['data']['p_val'][f]\n",
    "    print(f'{fname} -- {stat} {stat_val:.3f} -- p-value {p_val:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31e8d7b",
   "metadata": {},
   "source": [
    "Any of the feature's p-values are below the threshold value of p. The threshold p-value can be visible as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a670db6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005555555555555556"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds['data']['threshold']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d236d7d9",
   "metadata": {},
   "source": [
    "Now, Let's check the drift between the the second test set with reference set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87daa323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drift? No!\n"
     ]
    }
   ],
   "source": [
    "preds = cd.predict(X_t1)\n",
    "labels = ['No!', 'Yes!']\n",
    "print('Drift? {}'.format(labels[preds['data']['is_drift']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f481507e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregnancies -- Drift? No! -- K-S 0.016 -- p-value 0.642\n",
      "PlasmaGlucose -- Drift? No! -- K-S 0.010 -- p-value 0.985\n",
      "DiastolicBloodPressure -- Drift? No! -- K-S 0.015 -- p-value 0.677\n",
      "TricepsThickness -- Drift? No! -- K-S 0.017 -- p-value 0.503\n",
      "SerumInsulin -- Drift? No! -- K-S 0.016 -- p-value 0.571\n",
      "BMI -- Drift? No! -- K-S 0.020 -- p-value 0.351\n",
      "DiabetesPedigree -- Drift? No! -- K-S 0.013 -- p-value 0.844\n",
      "Age -- Drift? No! -- K-S 0.021 -- p-value 0.288\n",
      "Diabetic -- Drift? No! -- Chi2 0.002 -- p-value 1.000\n"
     ]
    }
   ],
   "source": [
    "for f in range(cd.n_features):\n",
    "    stat = 'Chi2' if f in list(categories_per_feature.keys()) else 'K-S'\n",
    "    fname = feature_names[f]\n",
    "    is_drift = (preds['data']['p_val'][f] < preds['data']['threshold']).astype(int)\n",
    "    stat_val, p_val = preds['data']['distance'][f], preds['data']['p_val'][f]\n",
    "    print(f'{fname} -- Drift? {labels[is_drift]} -- {stat} {stat_val:.3f} -- p-value {p_val:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a55a17c",
   "metadata": {},
   "source": [
    "# Chi-Square Drift\n",
    "\n",
    "While the TabularDrift detector works fine with numerical or categorical features only, we can also directly use a categorical drift detector. First we construct a categorical-only dataset and then use the ChiSquareDrift detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "25e97287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4500, 1), (4500, 1))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = list(category_map.keys())\n",
    "cat_names = [feature_names[_] for _ in list(category_map.keys())]\n",
    "X_ref_cat, X_t0_cat = X_ref[:, cols], X_t0[:, cols]\n",
    "X_ref_cat.shape, X_t0_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "596ae0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drift? No!\n"
     ]
    }
   ],
   "source": [
    "cd = ChiSquareDrift(X_ref_cat, p_val=.05)\n",
    "preds = cd.predict(X_t0_cat)\n",
    "print('Drift? {}'.format(labels[preds['data']['is_drift']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6ae52c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold 0.05\n",
      "Diabetic -- Drift? No! -- Chi2 0.963 -- p-value 0.326\n"
     ]
    }
   ],
   "source": [
    "print(f\"Threshold {preds['data']['threshold']}\")\n",
    "for f in range(cd.n_features):\n",
    "    fname = cat_names[f]\n",
    "    is_drift = (preds['data']['p_val'][f] < preds['data']['threshold']).astype(int)\n",
    "    stat_val, p_val = preds['data']['distance'][f], preds['data']['p_val'][f]\n",
    "    print(f'{fname} -- Drift? {labels[is_drift]} -- {stat} {stat_val:.3f} -- p-value {p_val:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8dd0a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
