{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5928c1cb",
   "metadata": {},
   "source": [
    "<hr />\n",
    "Example for Spark Streaming\n",
    "<hr />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428a0712",
   "metadata": {},
   "source": [
    "<hr />\n",
    "The following command adds the pyspark to sys.path at runtime. If the pyspark is not on the system path by default. It also prints the path of the spark.\n",
    "<hr />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf08928b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KanchanRushikeshKale\\spark\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "\n",
    "print(findspark.find())\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d07e82",
   "metadata": {},
   "source": [
    "<hr />\n",
    "Create a Spark Session\n",
    "<hr />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ea7e603",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"StructuredNetworkWordCount\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfb82d4",
   "metadata": {},
   "source": [
    "<hr />\n",
    "We use Netcat (a small utility found in most Unix-like systems) as a data server for providing the sentences to the streaming application. <br>\n",
    "\n",
    "Run the below command in the terminal to start the data server on port 9999. <br>\n",
    "nc -lk 9999 <br>\n",
    "\n",
    "install netcat for windows<br>\n",
    "https://nmap.org/download.html#windows <br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f5193e",
   "metadata": {},
   "source": [
    "<hr />\n",
    "Import the packages required to split a sentence into words.\n",
    "<hr />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b36ec95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "from pyspark.sql.functions import split "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c898e9e2",
   "metadata": {},
   "source": [
    "<hr />\n",
    "The variable \"lines\" is a DataFrame that represents an unbounded table containing the streaming text data. <br>\n",
    "The wordCounts DataFrame groups the unique values in the Dataset and counts them. <br>\n",
    "<hr />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0829501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame representing the stream of input lines from connection to localhost:9999\n",
    "lines = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"socket\") \\\n",
    "    .option(\"host\", \"localhost\") \\\n",
    "    .option(\"port\", 9999) \\\n",
    "    .load()\n",
    "\n",
    "# Split the lines into words\n",
    "words = lines.select(\n",
    "   explode(\n",
    "       split(lines.value, \" \")\n",
    "   ).alias(\"word\")\n",
    ")\n",
    "\n",
    "# Generate running word count\n",
    "wordCounts = words.groupBy(\"word\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a571e1",
   "metadata": {},
   "source": [
    "<hr />\n",
    "The streaming computation is started in the background. <br>\n",
    "The applications starts receiving data and computing the counts. <br>\n",
    "Further, dispalys the complete set of counts to the console every time they are updated. <br>\n",
    "\n",
    "After running the below cell, provide the input sentences in the data server terminal started earlier. <br>\n",
    "<hr />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9615ea",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Start running the query that prints the running counts to the console\n",
    "query = wordCounts \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .format(\"console\") \\\n",
    "    .start()\n",
    "\n",
    "query.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1ac288",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3cde31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
